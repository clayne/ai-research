{
  "last_node_id": 23,
  "last_link_id": 43,
  "nodes": [
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1620,
        320
      ],
      "size": {
        "0": 140,
        "1": 60
      },
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 7
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 12
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            9
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 11,
      "type": "Note",
      "pos": [
        420,
        -10
      ],
      "size": {
        "0": 260,
        "1": 230
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "LORA\n====\n\nSTRENGTH_MODEL and STRENGTH_CLIP are supposed to have the same value, but you can play with the values to get different results.\n\nThe CLIP is responsible of translating the prompts. The MODEL is the actual trained data.\n\n** LORAs can be daisy-chained! You can have as many as you want **"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 18,
      "type": "CLIPSetLastLayer",
      "pos": [
        -190,
        445
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 25,
          "slot_index": 0
        }
      ],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            26
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPSetLastLayer"
      },
      "widgets_values": [
        -2
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        820,
        400
      ],
      "size": {
        "0": 370,
        "1": 160
      },
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 41
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            6
          ],
          "slot_index": 0
        }
      ],
      "title": "CLIP Text Encode (Negative)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "pony, animal ears, animal, horns, anime blurry, illustration, toy, clay, low quality, flag, nasa, mission patch, score_4, score_5, score_6, monochrome, wings,  cloven hooves, cloven feet, hooves, glowing eyes, source_anime, \"score_6, (trans: 1.5), physique-in-detail: 2\", furry\n"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 15,
      "type": "VAELoader",
      "pos": [
        1250,
        640
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            12
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "taesdxl"
      ]
    },
    {
      "id": 21,
      "type": "LoraLoader",
      "pos": [
        135,
        731
      ],
      "size": {
        "0": 315,
        "1": 126
      },
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 32
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 34
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            37
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            38
          ],
          "shape": 3,
          "slot_index": 1
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoader"
      },
      "widgets_values": [
        "Pony\\Concept Art Twilight Style SDXL_LoRA_Pony Diffusion V6 XL.safetensors",
        0.32,
        0.32
      ]
    },
    {
      "id": 17,
      "type": "LoraLoader",
      "pos": [
        132,
        555
      ],
      "size": {
        "0": 315,
        "1": 126
      },
      "flags": {},
      "order": 6,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 43
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 26
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            32
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            34
          ],
          "shape": 3,
          "slot_index": 1
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoader"
      },
      "widgets_values": [
        "detailed_notrigger.safetensors",
        1.1400000000000001,
        1.11
      ]
    },
    {
      "id": 22,
      "type": "LoraLoader",
      "pos": [
        483,
        729
      ],
      "size": {
        "0": 315,
        "1": 126
      },
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 37
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 38
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            39
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            40,
            41
          ],
          "shape": 3,
          "slot_index": 1
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoader"
      },
      "widgets_values": [
        "Concept Art Ultimatum Style LoRA_Pony XL v6.safetensors",
        0.63,
        0.63
      ]
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": [
        -228,
        268
      ],
      "size": {
        "0": 328.5366516113281,
        "1": 98
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            42
          ],
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            25
          ],
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [],
          "slot_index": 2
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "PNY\\ponyFaetality_v10.safetensors"
      ]
    },
    {
      "id": 23,
      "type": "PerturbedAttention",
      "pos": [
        194,
        289
      ],
      "size": {
        "0": 315,
        "1": 130
      },
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 42
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            43
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "PerturbedAttention"
      },
      "widgets_values": [
        3,
        0,
        "middle",
        0
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        1264,
        109
      ],
      "size": {
        "0": 300,
        "1": 474
      },
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 39
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 2
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            7
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        1234787,
        "increment",
        31,
        4,
        "euler_ancestral",
        "sgm_uniform",
        1
      ]
    },
    {
      "id": 5,
      "type": "EmptyLatentImage",
      "pos": [
        970,
        620
      ],
      "size": {
        "0": 220,
        "1": 106
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            2
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        2
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        820,
        180
      ],
      "size": {
        "0": 370,
        "1": 160
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 40
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            4
          ],
          "slot_index": 0
        }
      ],
      "title": "CLIP Text Encode (Positive)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "score_9, score_8_up, score_8, score_9, \n\nstill life, dried flowers in ancient vase, runes engravings, potpourri, no humans, studio lights, rembradt Rubens style lighting and tones\n\ncinematic, dramatic lighting, high resolution, detailed, 4k"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1811,
        320
      ],
      "size": {
        "0": 410,
        "1": 460
      },
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 9
        }
      ],
      "properties": {},
      "widgets_values": [
        "Result"
      ]
    }
  ],
  "links": [
    [
      2,
      5,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      7,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      9,
      8,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      12,
      15,
      0,
      8,
      1,
      "VAE"
    ],
    [
      25,
      4,
      1,
      18,
      0,
      "CLIP"
    ],
    [
      26,
      18,
      0,
      17,
      1,
      "CLIP"
    ],
    [
      32,
      17,
      0,
      21,
      0,
      "MODEL"
    ],
    [
      34,
      17,
      1,
      21,
      1,
      "CLIP"
    ],
    [
      37,
      21,
      0,
      22,
      0,
      "MODEL"
    ],
    [
      38,
      21,
      1,
      22,
      1,
      "CLIP"
    ],
    [
      39,
      22,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      40,
      22,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      41,
      22,
      1,
      7,
      0,
      "CLIP"
    ],
    [
      42,
      4,
      0,
      23,
      0,
      "MODEL"
    ],
    [
      43,
      23,
      0,
      17,
      0,
      "MODEL"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {},
  "version": 0.4
}